{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b40edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from timeit import default_timer\n",
    "import torchvision\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a939224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datagen\n",
    "def datagen(batch_size = 1, device='cpu'):\n",
    "    while(True):\n",
    "        inp = torch.rand(batch_size, 3, 224, 224, dtype=torch.float32, device=device)\n",
    "        label = torch.rand(batch_size, 1000, dtype=torch.float32, device=device)\n",
    "        yield (inp, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55045468",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def timer(enable = True):\n",
    "    if not enable:\n",
    "        yield\n",
    "    else:\n",
    "        try:\n",
    "            start = default_timer()\n",
    "            yield\n",
    "        finally:\n",
    "            torch.cuda.synchronize()\n",
    "            stop = default_timer()\n",
    "            print(f'Time: {(stop - start) * 1000}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973459ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, opt, datagen, num_iter):\n",
    "    model.train()\n",
    "    num_iter = num_iter\n",
    "    for _ in range(num_iter):\n",
    "        inp, lbl = next(datagen)\n",
    "        with timer(enable=True) as t:\n",
    "            out = model(inp)\n",
    "            loss = loss_fn(out, lbl)\n",
    "            loss.backward()\n",
    "            opt.zero_grad()\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41aeb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cg(g, static_inp, static_lbl, data, num_iter):\n",
    "    for _ in range(num_iter):\n",
    "        inp, lbl = next(data)\n",
    "        with timer(enable=True) as t:\n",
    "            static_inp.copy_(inp)\n",
    "            static_lbl.copy_(lbl)\n",
    "            g.replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58939ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "Time: 164.3875688314438ms\n",
      "Time: 154.18434143066406ms\n",
      "Time: 154.29921820759773ms\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_iter = 100\n",
    "\n",
    "model = torchvision.models.resnet50().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "batch_size = 128\n",
    "\n",
    "### DATAGEN\n",
    "data = datagen(batch_size, device)\n",
    "\n",
    "### WARMUP\n",
    "train(model, loss_fn, opt, data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ae15a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n",
      "Time: 321.23929634690285ms\n",
      "Time: 370.78429386019707ms\n",
      "Time: 377.4437755346298ms\n",
      "Time: 375.01807883381844ms\n",
      "Time: 377.60650366544724ms\n",
      "Time: 382.1890316903591ms\n",
      "Time: 370.5022782087326ms\n",
      "Time: 385.4169398546219ms\n",
      "Time: 383.84488597512245ms\n",
      "Time: 374.608650803566ms\n",
      "Time: 378.77947464585304ms\n",
      "Time: 383.0159120261669ms\n",
      "Time: 385.30611991882324ms\n",
      "Time: 386.6407461464405ms\n",
      "Time: 388.49441334605217ms\n",
      "Time: 373.73048439621925ms\n",
      "Time: 382.7702924609184ms\n",
      "Time: 384.64372232556343ms\n",
      "Time: 389.25352320075035ms\n",
      "Time: 387.6347355544567ms\n",
      "Time: 383.311253041029ms\n",
      "Time: 380.1971711218357ms\n",
      "Time: 386.09829545021057ms\n",
      "Time: 383.5417330265045ms\n",
      "Time: 386.02547720074654ms\n",
      "Time: 388.1518207490444ms\n",
      "Time: 380.47298416495323ms\n",
      "Time: 388.4025812149048ms\n",
      "Time: 378.3841282129288ms\n",
      "Time: 381.9281794130802ms\n",
      "Time: 390.5490040779114ms\n",
      "Time: 379.3046772480011ms\n",
      "Time: 392.48355850577354ms\n",
      "Time: 383.18243622779846ms\n",
      "Time: 379.3654218316078ms\n",
      "Time: 387.1603533625603ms\n",
      "Time: 383.1409737467766ms\n",
      "Time: 396.44720777869225ms\n",
      "Time: 424.66240376234055ms\n",
      "Time: 424.49430376291275ms\n",
      "Time: 424.78491365909576ms\n",
      "Time: 419.05758529901505ms\n",
      "Time: 421.12166434526443ms\n",
      "Time: 427.43123322725296ms\n",
      "Time: 447.8096291422844ms\n",
      "Time: 451.2847028672695ms\n",
      "Time: 447.0805414021015ms\n",
      "Time: 442.2018937766552ms\n",
      "Time: 448.59296828508377ms\n",
      "Time: 492.4585111439228ms\n",
      "Time: 534.3507528305054ms\n",
      "Time: 530.2217788994312ms\n",
      "Time: 530.0066769123077ms\n",
      "Time: 530.5862538516521ms\n",
      "Time: 532.2458855807781ms\n",
      "Time: 529.8539362847805ms\n",
      "Time: 534.1974832117558ms\n",
      "Time: 530.3409323096275ms\n",
      "Time: 530.0851874053478ms\n",
      "Time: 534.0829640626907ms\n",
      "Time: 530.4784066975117ms\n",
      "Time: 529.9939662218094ms\n",
      "Time: 534.2155285179615ms\n",
      "Time: 531.7163616418839ms\n",
      "Time: 530.0383865833282ms\n",
      "Time: 534.2444069683552ms\n",
      "Time: 530.2981995046139ms\n",
      "Time: 529.8553667962551ms\n",
      "Time: 534.3999937176704ms\n",
      "Time: 530.2543789148331ms\n",
      "Time: 529.9106016755104ms\n",
      "Time: 534.197524189949ms\n",
      "Time: 530.6193381547928ms\n",
      "Time: 530.0150625407696ms\n",
      "Time: 528.64920347929ms\n",
      "Time: 535.1884812116623ms\n",
      "Time: 530.0118289887905ms\n",
      "Time: 534.1994613409042ms\n",
      "Time: 530.5575765669346ms\n",
      "Time: 530.1291756331921ms\n",
      "Time: 535.2728106081486ms\n",
      "Time: 529.959786683321ms\n",
      "Time: 530.5834077298641ms\n",
      "Time: 531.7261405289173ms\n",
      "Time: 530.3612016141415ms\n",
      "Time: 529.7227092087269ms\n",
      "Time: 534.2091247439384ms\n",
      "Time: 530.6460820138454ms\n",
      "Time: 530.2843935787678ms\n",
      "Time: 540.9946069121361ms\n",
      "Time: 539.8807302117348ms\n",
      "Time: 540.8861339092255ms\n",
      "Time: 542.1256646513939ms\n",
      "Time: 543.3334037661552ms\n",
      "Time: 539.990272372961ms\n",
      "Time: 538.6140085756779ms\n",
      "Time: 535.4978404939175ms\n",
      "Time: 534.0866446495056ms\n",
      "Time: 532.4962623417377ms\n",
      "Time: 537.0423831045628ms\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training Started')\n",
    "train(model, loss_fn, opt, data, num_iter)\n",
    "print('Training Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d4eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Graph Training Started\n",
      "Time: 155.4575152695179ms\n",
      "Time: 161.14727780222893ms\n",
      "Time: 172.48966172337532ms\n",
      "Time: 172.34009131789207ms\n",
      "Time: 168.95577311515808ms\n",
      "Time: 163.2806472480297ms\n",
      "Time: 168.46423596143723ms\n",
      "Time: 186.6588443517685ms\n",
      "Time: 255.35886734724045ms\n",
      "Time: 270.74969559907913ms\n",
      "Time: 275.9062945842743ms\n",
      "Time: 284.33337062597275ms\n",
      "Time: 280.3274691104889ms\n",
      "Time: 281.9564491510391ms\n",
      "Time: 278.3804051578045ms\n",
      "Time: 274.300180375576ms\n",
      "Time: 277.1734707057476ms\n",
      "Time: 290.35187512636185ms\n",
      "Time: 313.6036656796932ms\n",
      "Time: 313.472256064415ms\n",
      "Time: 300.31537637114525ms\n",
      "Time: 314.2014890909195ms\n",
      "Time: 355.7199090719223ms\n",
      "Time: 356.15959390997887ms\n",
      "Time: 352.2270806133747ms\n",
      "Time: 357.5357720255852ms\n",
      "Time: 362.9982881247997ms\n",
      "Time: 366.3595952093601ms\n",
      "Time: 359.4311624765396ms\n",
      "Time: 351.4114320278168ms\n",
      "Time: 355.26909306645393ms\n",
      "Time: 352.2370830178261ms\n",
      "Time: 364.85184356570244ms\n",
      "Time: 385.47782972455025ms\n",
      "Time: 386.76170632243156ms\n",
      "Time: 383.4626004099846ms\n",
      "Time: 387.8740146756172ms\n",
      "Time: 380.5077075958252ms\n",
      "Time: 387.13328167796135ms\n",
      "Time: 410.3534147143364ms\n",
      "Time: 432.62602761387825ms\n",
      "Time: 440.2000866830349ms\n",
      "Time: 442.2747790813446ms\n",
      "Time: 431.71973153948784ms\n",
      "Time: 447.1293278038502ms\n",
      "Time: 447.1885412931442ms\n",
      "Time: 444.9330121278763ms\n",
      "Time: 442.57254153490067ms\n",
      "Time: 437.76910379529ms\n",
      "Time: 446.592852473259ms\n",
      "Time: 442.26544722914696ms\n",
      "Time: 469.0757095813751ms\n",
      "Time: 513.0840502679348ms\n",
      "Time: 513.9779187738895ms\n",
      "Time: 519.0489403903484ms\n",
      "Time: 512.842632830143ms\n",
      "Time: 518.9632140100002ms\n",
      "Time: 512.2168809175491ms\n",
      "Time: 519.0122909843922ms\n",
      "Time: 513.9326341450214ms\n",
      "Time: 504.49762865900993ms\n",
      "Time: 510.4740597307682ms\n",
      "Time: 512.1197551488876ms\n",
      "Time: 512.2933238744736ms\n",
      "Time: 510.0873149931431ms\n",
      "Time: 506.7860297858715ms\n",
      "Time: 513.3383423089981ms\n",
      "Time: 509.1819614171982ms\n",
      "Time: 519.1563852131367ms\n",
      "Time: 509.3347690999508ms\n",
      "Time: 514.2129473388195ms\n",
      "Time: 516.3226090371609ms\n",
      "Time: 508.81513208150864ms\n",
      "Time: 512.5939548015594ms\n",
      "Time: 513.6067382991314ms\n",
      "Time: 506.6480524837971ms\n",
      "Time: 508.0246701836586ms\n",
      "Time: 512.7862878143787ms\n",
      "Time: 506.1265416443348ms\n",
      "Time: 516.5552049875259ms\n",
      "Time: 509.03017446398735ms\n",
      "Time: 508.7420418858528ms\n",
      "Time: 519.2295461893082ms\n",
      "Time: 511.9578242301941ms\n",
      "Time: 516.3604393601418ms\n",
      "Time: 512.5323310494423ms\n",
      "Time: 514.4269838929176ms\n",
      "Time: 511.8364803493023ms\n",
      "Time: 512.0879076421261ms\n",
      "Time: 515.3253562748432ms\n",
      "Time: 505.59359043836594ms\n",
      "Time: 506.91109523177147ms\n",
      "Time: 510.8078643679619ms\n",
      "Time: 507.7752619981766ms\n",
      "Time: 514.5493000745773ms\n",
      "Time: 515.2207873761654ms\n",
      "Time: 511.4489868283272ms\n",
      "Time: 514.0055269002914ms\n",
      "Time: 511.70121133327484ms\n",
      "Time: 518.0380381643772ms\n",
      "CUDA Graph Training Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = torch.cuda.CUDAGraph()\n",
    "static_inp = torch.randn(batch_size, 3, 224, 224, device=device)\n",
    "static_lbl = torch.randn(batch_size, 1000, device=device)\n",
    "opt.zero_grad()\n",
    "with torch.cuda.graph(g):\n",
    "    model.train()\n",
    "    static_out = model(static_inp)\n",
    "    static_loss = loss_fn(static_out, static_lbl)\n",
    "    static_loss.backward()\n",
    "    opt.step()\n",
    "### CUDA Graph Train\n",
    "print('CUDA Graph Training Started')\n",
    "train_cg(g, static_inp, static_lbl, data, num_iter)\n",
    "print('CUDA Graph Training Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a758a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
